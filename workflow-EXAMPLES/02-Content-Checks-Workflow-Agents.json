{
  "nodes": [
    {
      "id": "startAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 450.8705505632962,
        "y": 51.74110112659224
      },
      "width": 296,
      "height": 66,
      "selected": false,
      "positionAbsolute": {
        "x": 450.8705505632962,
        "y": 51.74110112659224
      },
      "data": {
        "id": "startAgentflow_0",
        "label": "Start: User provides Original Topic",
        "version": 1.1,
        "name": "startAgentflow",
        "type": "Start",
        "color": "#7EE787",
        "hideInput": true,
        "baseClasses": [
          "Start"
        ],
        "category": "Agent Flows",
        "description": "Starting point of the agentflow",
        "inputParams": [
          {
            "label": "Input Type",
            "name": "startInputType",
            "type": "options",
            "options": [
              {
                "label": "Chat Input",
                "name": "chatInput",
                "description": "Start the conversation with chat input"
              },
              {
                "label": "Form Input",
                "name": "formInput",
                "description": "Start the workflow with form inputs"
              }
            ],
            "default": "chatInput",
            "id": "startAgentflow_0-input-startInputType-options",
            "display": true
          },
          {
            "label": "Form Title",
            "name": "formTitle",
            "type": "string",
            "placeholder": "Please Fill Out The Form",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formTitle-string",
            "display": false
          },
          {
            "label": "Form Description",
            "name": "formDescription",
            "type": "string",
            "placeholder": "Complete all fields below to continue",
            "show": {
              "startInputType": "formInput"
            },
            "id": "startAgentflow_0-input-formDescription-string",
            "display": false
          },
          {
            "label": "Form Input Types",
            "name": "formInputTypes",
            "description": "Specify the type of form input",
            "type": "array",
            "show": {
              "startInputType": "formInput"
            },
            "array": [
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Options",
                    "name": "options"
                  }
                ],
                "default": "string"
              },
              {
                "label": "Label",
                "name": "label",
                "type": "string",
                "placeholder": "Label for the input"
              },
              {
                "label": "Variable Name",
                "name": "name",
                "type": "string",
                "placeholder": "Variable name for the input (must be camel case)",
                "description": "Variable name must be camel case. For example: firstName, lastName, etc."
              },
              {
                "label": "Add Options",
                "name": "addOptions",
                "type": "array",
                "show": {
                  "formInputTypes[$index].type": "options"
                },
                "array": [
                  {
                    "label": "Option",
                    "name": "option",
                    "type": "string"
                  }
                ]
              }
            ],
            "id": "startAgentflow_0-input-formInputTypes-array",
            "display": false
          },
          {
            "label": "Ephemeral Memory",
            "name": "startEphemeralMemory",
            "type": "boolean",
            "description": "Start fresh for every execution without past chat history",
            "optional": true,
            "id": "startAgentflow_0-input-startEphemeralMemory-boolean",
            "display": true
          },
          {
            "label": "Flow State",
            "name": "startState",
            "description": "Runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string",
                "placeholder": "Foo"
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "placeholder": "Bar",
                "optional": true
              }
            ],
            "id": "startAgentflow_0-input-startState-array",
            "display": true
          },
          {
            "label": "Persist State",
            "name": "startPersistState",
            "type": "boolean",
            "description": "Persist the state in the same session",
            "optional": true,
            "id": "startAgentflow_0-input-startPersistState-boolean",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "startInputType": "chatInput",
          "startEphemeralMemory": "",
          "startState": [
            {
              "key": "original_topic",
              "value": "{{question}}"
            },
            {
              "key": "raw_insights",
              "value": "\\\\"
            }
          ],
          "startPersistState": true
        },
        "outputAnchors": [
          {
            "id": "startAgentflow_0-output-startAgentflow",
            "label": "Start",
            "name": "startAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "executeFlowAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 450,
        "y": 415
      },
      "width": 282,
      "height": 66,
      "selected": false,
      "positionAbsolute": {
        "x": 450,
        "y": 415
      },
      "data": {
        "id": "executeFlowAgentflow_0",
        "label": "Conversation Loop (Agent 0 & 1)",
        "version": 1.1,
        "name": "executeFlowAgentflow",
        "type": "ExecuteFlow",
        "color": "#a3b18a",
        "baseClasses": [
          "ExecuteFlow"
        ],
        "category": "Agent Flows",
        "description": "Execute another flow",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "chatflowApi"
            ],
            "optional": true,
            "id": "executeFlowAgentflow_0-input-credential-credential",
            "display": true
          },
          {
            "label": "Select Flow",
            "name": "executeFlowSelectedFlow",
            "type": "asyncOptions",
            "loadMethod": "listFlows",
            "id": "executeFlowAgentflow_0-input-executeFlowSelectedFlow-asyncOptions",
            "display": true
          },
          {
            "label": "Input",
            "name": "executeFlowInput",
            "type": "string",
            "rows": 4,
            "acceptVariable": true,
            "id": "executeFlowAgentflow_0-input-executeFlowInput-string",
            "display": true
          },
          {
            "label": "Override Config",
            "name": "executeFlowOverrideConfig",
            "description": "Override the config passed to the flow",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "id": "executeFlowAgentflow_0-input-executeFlowOverrideConfig-json",
            "display": true
          },
          {
            "label": "Base URL",
            "name": "executeFlowBaseURL",
            "type": "string",
            "description": "Base URL to Flowise. By default, it is the URL of the incoming request. Useful when you need to execute flow through an alternative route.",
            "placeholder": "http://localhost:3000",
            "optional": true,
            "id": "executeFlowAgentflow_0-input-executeFlowBaseURL-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "executeFlowReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "executeFlowAgentflow_0-input-executeFlowReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "executeFlowUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "executeFlowAgentflow_0-input-executeFlowUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "executeFlowSelectedFlow": "b60743b4-6101-4428-af7e-a99290d37673",
          "executeFlowInput": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.original_topic\" data-label=\"$flow.state.original_topic\">{{ $flow.state.original_topic }}</span></p>",
          "executeFlowOverrideConfig": "",
          "executeFlowBaseURL": "http://localhost:3001",
          "executeFlowReturnResponseAs": "userMessage",
          "executeFlowUpdateState": [
            {
              "key": "raw_insights",
              "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output\" data-label=\"output\">{{ output }}</span> </p>"
            }
          ]
        },
        "outputAnchors": [
          {
            "id": "executeFlowAgentflow_0-output-executeFlowAgentflow",
            "label": "Execute Flow",
            "name": "executeFlowAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "agentAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 450,
        "y": 900
      },
      "width": 222,
      "height": 101,
      "selected": false,
      "positionAbsolute": {
        "x": 450,
        "y": 900
      },
      "data": {
        "id": "agentAgentflow_0",
        "label": "Duplicate Check Agent",
        "version": 2,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_0-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_0-input-agentMessages-array",
            "display": true
          },
          {
            "label": "OpenAI Built-in Tools",
            "name": "agentToolsBuiltInOpenAI",
            "type": "multiOptions",
            "optional": true,
            "options": [
              {
                "label": "Web Search",
                "name": "web_search_preview",
                "description": "Search the web for the latest information"
              },
              {
                "label": "Code Interpreter",
                "name": "code_interpreter",
                "description": "Write and run Python code in a sandboxed environment"
              },
              {
                "label": "Image Generation",
                "name": "image_generation",
                "description": "Generate images based on a text prompt"
              }
            ],
            "show": {
              "agentModel": "chatOpenAI"
            },
            "id": "agentAgentflow_0-input-agentToolsBuiltInOpenAI-multiOptions",
            "display": false
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_0-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_0-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_0-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_0-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_0-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_0-input-agentUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_0-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_0-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatOpenRouter",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>You are a meticulous Archivist AI. Your primary function is to maintain the integrity of a knowledge archive by preventing duplicate information.</p><p>You have read-only access to an archive via a <strong>Google Drive tool</strong>. Your sole task is to analyze the user's latest input (a new insight) and compare it against the contents of the archive.</p><ul><li><p>If the insight introduces a new concept, a fresh perspective, or data not previously covered in the archive, it is <strong>NOVEL</strong>.</p></li><li><p>If the insight rehashes, rephrases, or is thematically identical to information already in the archive, it is <strong>REDUNDANT</strong>.</p></li></ul><p>You must respond with <strong>only a single word</strong>: <code>NOVEL</code> or <code>REDUNDANT</code>. Do not provide any explanation, preamble, or punctuation. Your entire output must be one of these two words.</p>"
            }
          ],
          "agentTools": [
            {
              "agentSelectedTool": "googleDriveTool",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "driveType": "folder",
                "folderActions": "[\"listFolderContents\"]",
                "agentSelectedTool": "googleDriveTool"
              }
            }
          ],
          "agentKnowledgeDocumentStores": "",
          "agentKnowledgeVSEmbeddings": "",
          "agentEnableMemory": true,
          "agentMemoryType": "allMessages",
          "agentUserMessage": "<p>Analyze the following new insight against the archive and determine if it is NOVEL or REDUNDANT. New Insight: \"<span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.raw_insights\" data-label=\"$flow.state.raw_insights\">{{ $flow.state.raw_insights }}</span>\" . Filter on last date modified first using \"<span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span>\"</p>",
          "agentReturnResponseAs": "userMessage",
          "agentUpdateState": "",
          "agentModelConfig": {
            "cache": "",
            "modelName": "x-ai/grok-4-fast:free",
            "temperature": "1",
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "https://openrouter.ai/api/v1",
            "baseOptions": "",
            "agentModel": "chatOpenRouter"
          }
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_0-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "conditionAgentAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 450,
        "y": 1625
      },
      "width": 222,
      "height": 80,
      "selected": false,
      "positionAbsolute": {
        "x": 450,
        "y": 1625
      },
      "data": {
        "id": "conditionAgentAgentflow_0",
        "label": "Router",
        "version": 1.1,
        "name": "conditionAgentAgentflow",
        "type": "ConditionAgent",
        "color": "#ff8fab",
        "baseClasses": [
          "ConditionAgent"
        ],
        "category": "Agent Flows",
        "description": "Utilize an agent to split flows based on dynamic conditions",
        "inputParams": [
          {
            "label": "Model",
            "name": "conditionAgentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "conditionAgentAgentflow_0-input-conditionAgentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Instructions",
            "name": "conditionAgentInstructions",
            "type": "string",
            "description": "A general instructions of what the condition agent should do",
            "rows": 4,
            "acceptVariable": true,
            "placeholder": "Determine if the user is interested in learning about AI",
            "id": "conditionAgentAgentflow_0-input-conditionAgentInstructions-string",
            "display": true
          },
          {
            "label": "Input",
            "name": "conditionAgentInput",
            "type": "string",
            "description": "Input to be used for the condition agent",
            "rows": 4,
            "acceptVariable": true,
            "default": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"question\" data-label=\"question\">{{ question }}</span> </p>",
            "id": "conditionAgentAgentflow_0-input-conditionAgentInput-string",
            "display": true
          },
          {
            "label": "Scenarios",
            "name": "conditionAgentScenarios",
            "description": "Define the scenarios that will be used as the conditions to split the flow",
            "type": "array",
            "array": [
              {
                "label": "Scenario",
                "name": "scenario",
                "type": "string",
                "placeholder": "User is asking for a pizza"
              }
            ],
            "default": [
              {
                "scenario": ""
              },
              {
                "scenario": ""
              }
            ],
            "id": "conditionAgentAgentflow_0-input-conditionAgentScenarios-array",
            "display": true
          },
          {
            "label": "Override System Prompt",
            "name": "conditionAgentOverrideSystemPrompt",
            "type": "boolean",
            "description": "Override initial system prompt for Condition Agent",
            "optional": true,
            "id": "conditionAgentAgentflow_0-input-conditionAgentOverrideSystemPrompt-boolean",
            "display": true
          },
          {
            "label": "Node System Prompt",
            "name": "conditionAgentSystemPrompt",
            "type": "string",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "default": "<p>You are part of a multi-agent system designed to make agent coordination and execution easy. Your task is to analyze the given input and select one matching scenario from a provided set of scenarios.</p>\n    <ul>\n        <li><strong>Input</strong>: A string representing the user's query, message or data.</li>\n        <li><strong>Scenarios</strong>: A list of predefined scenarios that relate to the input.</li>\n        <li><strong>Instruction</strong>: Determine which of the provided scenarios is the best fit for the input.</li>\n    </ul>\n    <h2>Steps</h2>\n    <ol>\n        <li><strong>Read the input string</strong> and the list of scenarios.</li>\n        <li><strong>Analyze the content of the input</strong> to identify its main topic or intention.</li>\n        <li><strong>Compare the input with each scenario</strong>: Evaluate how well the input's topic or intention aligns with each of the provided scenarios and select the one that is the best fit.</li>\n        <li><strong>Output the result</strong>: Return the selected scenario in the specified JSON format.</li>\n    </ol>\n    <h2>Output Format</h2>\n    <p>Output should be a JSON object that names the selected scenario, like this: <code>{\"output\": \"<selected_scenario_name>\"}</code>. No explanation is needed.</p>\n    <h2>Examples</h2>\n    <ol>\n       <li>\n            <p><strong>Input</strong>: <code>{\"input\": \"Hello\", \"scenarios\": [\"user is asking about AI\", \"user is not asking about AI\"], \"instruction\": \"Your task is to check if the user is asking about AI.\"}</code></p>\n            <p><strong>Output</strong>: <code>{\"output\": \"user is not asking about AI\"}</code></p>\n        </li>\n        <li>\n            <p><strong>Input</strong>: <code>{\"input\": \"What is AIGC?\", \"scenarios\": [\"user is asking about AI\", \"user is asking about the weather\"], \"instruction\": \"Your task is to check and see if the user is asking a topic about AI.\"}</code></p>\n            <p><strong>Output</strong>: <code>{\"output\": \"user is asking about AI\"}</code></p>\n        </li>\n        <li>\n            <p><strong>Input</strong>: <code>{\"input\": \"Can you explain deep learning?\", \"scenarios\": [\"user is interested in AI topics\", \"user wants to order food\"], \"instruction\": \"Determine if the user is interested in learning about AI.\"}</code></p>\n            <p><strong>Output</strong>: <code>{\"output\": \"user is interested in AI topics\"}</code></p>\n        </li>\n    </ol>\n    <h2>Note</h2>\n    <ul>\n        <li>Ensure that the input scenarios align well with potential user queries for accurate matching.</li>\n        <li>DO NOT include anything other than the JSON in your response.</li>\n    </ul>",
            "description": "Expert use only. Modifying this can significantly alter agent behavior. Leave default if unsure",
            "show": {
              "conditionAgentOverrideSystemPrompt": true
            },
            "id": "conditionAgentAgentflow_0-input-conditionAgentSystemPrompt-string",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "conditionAgentModel": "chatOpenRouter",
          "conditionAgentInstructions": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"chat_history\" data-label=\"chat_history\">{{ chat_history }}</span> You are an archivist. Your task is to determine if the provided new insight is novel or redundant compared to the existing archive. Respond with only one of two words: 'NOVEL' or 'REDUNDANT'.</p>",
          "conditionAgentInput": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.raw_insights\" data-label=\"$flow.state.raw_insights\">{{ $flow.state.raw_insights }}</span></p>",
          "conditionAgentScenarios": [
            {
              "scenario": "**Condition 1:** Output contains 'NOVEL'"
            },
            {
              "scenario": "**Condition 2:** Output contains 'REDUNDANT'"
            }
          ],
          "conditionAgentOverrideSystemPrompt": true,
          "conditionAgentModelConfig": {
            "cache": "",
            "modelName": "x-ai/grok-4-fast:free",
            "temperature": "1",
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "https://openrouter.ai/api/v1",
            "baseOptions": "",
            "conditionAgentModel": "chatOpenRouter"
          },
          "conditionAgentSystemPrompt": "<p>You are a meticulous Archivist AI. Your sole function is to analyze the provided input, which represents a new insight, and determine if it is substantively new or a repetition of information already known.</p><ul><li><p>If the insight introduces a new concept, a fresh perspective, or data not previously covered, it is <strong>NOVEL</strong>.</p></li><li><p>If the insight rehashes, rephrases, or is thematically identical to existing information, it is <strong>REDUNDANT</strong>.</p></li></ul><p>You must respond with <strong>only a single word</strong>: <code>NOVEL</code> or <code>REDUNDANT</code>. Do not provide any explanation, preamble, or punctuation. Your entire output must be one of these two words.</p>"
        },
        "outputAnchors": [
          {
            "id": "conditionAgentAgentflow_0-output-0",
            "label": "Condition Agent",
            "name": "conditionAgentAgentflow"
          },
          {
            "id": "conditionAgentAgentflow_0-output-1",
            "label": "Condition Agent",
            "name": "conditionAgentAgentflow"
          }
        ],
        "outputs": {
          "conditionAgentAgentflow": ""
        },
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "llmAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 50,
        "y": 2056
      },
      "width": 240,
      "height": 73,
      "selected": false,
      "positionAbsolute": {
        "x": 50,
        "y": 2056
      },
      "data": {
        "id": "llmAgentflow_0",
        "label": "Prompt Refinement Agent",
        "version": 1,
        "name": "llmAgentflow",
        "type": "LLM",
        "color": "#64B5F6",
        "baseClasses": [
          "LLM"
        ],
        "category": "Agent Flows",
        "description": "Large language models to analyze user-provided inputs and generate responses",
        "inputParams": [
          {
            "label": "Model",
            "name": "llmModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "llmAgentflow_0-input-llmModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "llmMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "llmAgentflow_0-input-llmMessages-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "llmEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "llmAgentflow_0-input-llmEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "llmMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "llmMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "llmMemoryType": "windowSize"
            },
            "id": "llmAgentflow_0-input-llmMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "llmMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "llmMemoryType": "conversationSummaryBuffer"
            },
            "id": "llmAgentflow_0-input-llmMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "llmUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "llmEnableMemory": true
            },
            "id": "llmAgentflow_0-input-llmUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "llmReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "llmAgentflow_0-input-llmReturnResponseAs-options",
            "display": true
          },
          {
            "label": "JSON Structured Output",
            "name": "llmStructuredOutput",
            "description": "Instruct the LLM to give output in a JSON structured schema",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "string"
              },
              {
                "label": "Type",
                "name": "type",
                "type": "options",
                "options": [
                  {
                    "label": "String",
                    "name": "string"
                  },
                  {
                    "label": "String Array",
                    "name": "stringArray"
                  },
                  {
                    "label": "Number",
                    "name": "number"
                  },
                  {
                    "label": "Boolean",
                    "name": "boolean"
                  },
                  {
                    "label": "Enum",
                    "name": "enum"
                  },
                  {
                    "label": "JSON Array",
                    "name": "jsonArray"
                  }
                ]
              },
              {
                "label": "Enum Values",
                "name": "enumValues",
                "type": "string",
                "placeholder": "value1, value2, value3",
                "description": "Enum values. Separated by comma",
                "optional": true,
                "show": {
                  "llmStructuredOutput[$index].type": "enum"
                }
              },
              {
                "label": "JSON Schema",
                "name": "jsonSchema",
                "type": "code",
                "placeholder": "{\n    \"answer\": {\n        \"type\": \"string\",\n        \"description\": \"Value of the answer\"\n    },\n    \"reason\": {\n        \"type\": \"string\",\n        \"description\": \"Reason for the answer\"\n    },\n    \"optional\": {\n        \"type\": \"boolean\"\n    },\n    \"count\": {\n        \"type\": \"number\"\n    },\n    \"children\": {\n        \"type\": \"array\",\n        \"items\": {\n            \"type\": \"object\",\n            \"properties\": {\n                \"value\": {\n                    \"type\": \"string\",\n                    \"description\": \"Value of the children's answer\"\n                }\n            }\n        }\n    }\n}",
                "description": "JSON schema for the structured output",
                "optional": true,
                "hideCodeExecute": true,
                "show": {
                  "llmStructuredOutput[$index].type": "jsonArray"
                }
              },
              {
                "label": "Description",
                "name": "description",
                "type": "string",
                "placeholder": "Description of the key"
              }
            ],
            "id": "llmAgentflow_0-input-llmStructuredOutput-array",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "llmUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "llmAgentflow_0-input-llmUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "llmModel": "chatOpenRouter",
          "llmMessages": [
            {
              "role": "system",
              "content": "<p>You are a creative AI Prompt Engineer. Your task is to overcome redundancy in a research process by generating a new line of inquiry based on today's date \"<span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span>\" .</p><p>You will receive a prompt that has led to repetitive or unoriginal information. Your job is to create a <strong>new, more specific prompt</strong> on the same general topic that steers the conversation in a fresh direction.</p><p><strong>Crucially, you must output only the text of the new prompt.</strong> Do not include any explanations, conversational text like \"Here is the new prompt:\", or quotation marks. Your entire response must be the new prompt, ready for the next agent to use. </p>"
            }
          ],
          "llmEnableMemory": true,
          "llmMemoryType": "allMessages",
          "llmUserMessage": "<p>The previous discussion on the topic \"<span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.original_topic\" data-label=\"$flow.state.original_topic\">{{ $flow.state.original_topic }}</span>\" has become redundant. Generate a new, more specific prompt that explores a different angle of this topic to get novel insights. Always specify the \"<span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span>\" in the new generated prompt. </p>",
          "llmReturnResponseAs": "userMessage",
          "llmStructuredOutput": "",
          "llmUpdateState": [
            {
              "key": "",
              "value": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"output\" data-label=\"output\">{{ output }}</span> </p>"
            }
          ],
          "llmModelConfig": {
            "cache": "",
            "modelName": "x-ai/grok-4-fast:free",
            "temperature": "1",
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "https://openrouter.ai/api/v1",
            "baseOptions": "",
            "llmModel": "chatOpenRouter"
          }
        },
        "outputAnchors": [
          {
            "id": "llmAgentflow_0-output-llmAgentflow",
            "label": "LLM",
            "name": "llmAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "loopAgentflow_0",
      "type": "agentFlow",
      "position": {
        "x": 50,
        "y": 2707
      },
      "width": 211,
      "height": 66,
      "selected": false,
      "positionAbsolute": {
        "x": 50,
        "y": 2707
      },
      "data": {
        "id": "loopAgentflow_0",
        "label": "Loop to Conversation",
        "version": 1,
        "name": "loopAgentflow",
        "type": "Loop",
        "color": "#FFA07A",
        "hideOutput": true,
        "baseClasses": [
          "Loop"
        ],
        "category": "Agent Flows",
        "description": "Loop back to a previous node",
        "inputParams": [
          {
            "label": "Loop Back To",
            "name": "loopBackToNode",
            "type": "asyncOptions",
            "loadMethod": "listPreviousNodes",
            "freeSolo": true,
            "id": "loopAgentflow_0-input-loopBackToNode-asyncOptions",
            "display": true
          },
          {
            "label": "Max Loop Count",
            "name": "maxLoopCount",
            "type": "number",
            "default": 5,
            "id": "loopAgentflow_0-input-maxLoopCount-number",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "loopBackToNode": "executeFlowAgentflow_0-Conversation Loop (Agent 0 & 1)",
          "maxLoopCount": "10"
        },
        "outputAnchors": [],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "agentAgentflow_1",
      "type": "agentFlow",
      "position": {
        "x": 850,
        "y": 2056
      },
      "width": 341,
      "height": 101,
      "selected": false,
      "positionAbsolute": {
        "x": 850,
        "y": 2056
      },
      "data": {
        "id": "agentAgentflow_1",
        "label": "Agent 2 (Synthesizer)",
        "version": 2,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_1-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_1-input-agentMessages-array",
            "display": true
          },
          {
            "label": "OpenAI Built-in Tools",
            "name": "agentToolsBuiltInOpenAI",
            "type": "multiOptions",
            "optional": true,
            "options": [
              {
                "label": "Web Search",
                "name": "web_search_preview",
                "description": "Search the web for the latest information"
              },
              {
                "label": "Code Interpreter",
                "name": "code_interpreter",
                "description": "Write and run Python code in a sandboxed environment"
              },
              {
                "label": "Image Generation",
                "name": "image_generation",
                "description": "Generate images based on a text prompt"
              }
            ],
            "show": {
              "agentModel": "chatOpenAI"
            },
            "id": "agentAgentflow_1-input-agentToolsBuiltInOpenAI-multiOptions",
            "display": false
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_1-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_1-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_1-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_1-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_1-input-agentMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_1-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_1-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_1-input-agentUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_1-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_1-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatOpenRouter",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>You are an expert Research Analyst and Synthesizer AI. Your task is to transform a collection of raw, unstructured insights into a polished, professional, up-to-date <span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span> white paper that synthesizes connections and narratives rather than merely summarizing.</p><h2>Process Steps</h2><ol><li><p><strong>Deep Analysis</strong>: Examine all provided insights to identify core themes, patterns, contradictions, and gaps. Extract key facts, evidence, and recurring perspectives.</p></li><li><p><strong>Logical Synthesis</strong>: Develop a cohesive narrative by connecting themes through shared factors, causal relationships, or comparative insights. Ensure academic rigor and logical flow.</p></li><li><p><strong>Structural Planning</strong>: Organize sections dynamically based on content complexity (e.g., problem statement, methodology, findings, implications, future outlook). Include tables/figures only if insights support them.</p></li><li><p><strong>Formal Writing</strong>: Compose content in clear, formal academic language. Maintain objectivity, depth, and logical transitions between sections.</p></li></ol><h2>Output Format</h2><p>A complete white paper in Markdown format:</p><ul><li><p><strong>Title</strong>: Concise yet informative</p></li><li><p><strong>Abstract</strong>: 150-word summary of objectives, methodology, findings, and implications</p></li><li><p><strong>Introduction</strong>: Context, problem statement, and research objectives (300-500 words)</p></li><li><p><strong>Sections</strong>: 4+ thematic subsections mirroring synthesized insights (1,200+ words total)</p></li><li><p><strong>Conclusion</strong>: Synthesis of insights, limitations, and forward-looking statements</p></li><li><p><strong>References</strong>: Citations to external sources (if applicable)</p></li><li><p><strong>Length</strong>: 2,000-3,000 words total. Use formal language, avoid colloquialisms.</p></li></ul><h2>Examples</h2><p><strong>Example 1: Processing Insights on Climate PolicyInput</strong>: Raw insights include:</p><ul><li><p>20% increase in solar adoption (2022-2025)</p></li><li><p>Subsidy removal correlations with 15% decline in regional projects</p></li><li><p>Interviews highlighting grid infrastructure gaps</p></li><li><p>Projections showing 75% renewable potential by 2042</p></li></ul><p><strong>Reasoning</strong>:</p><ol><li><p>Core themes: Policy efficacy, adoption barriers, future potential.</p></li><li><p>Narrative arc: Adoption surges via subsidies → Post-subsidy decline reveals infrastructure limits → Contrast with optimistic projections.</p></li><li><p>Structure: Introduction → Policy Impact Analysis → Infrastructure Challenges → Efficacy Assessment → Future Outlook.</p></li></ol><p><strong>Output</strong>:</p><pre><code class=\"language-markdown\"># Title: Policy Drivers and Infrastructure Barriers in Solar Energy Transition  \n## Abstract  \nThis paper analyzes the impact of subsidy policies on solar adoption, identifying their critical role in accelerating deployment while revealing persistent grid integration challenges that limit scalability. Based on 2022-2025 data, we project renewable energy pathways under varying policy scenarios... \n\n## Introduction  \nBackground on global solar energy expansion... Research questions focus on:  \n1. Subsidy sensitivity periods  \n2. Infrastructure capacity thresholds  \n3. Policy adjustment recommendations... \n\n## Subsidy Impact Assessment  \nQuantitative analysis shows 20% adoption growth during subsidy eligibility (2022-2025). Regression models indicate tax removal correlates with 15.2% project decline (p&lt;0.01)... \n\n## Infrastructure Limitations  \nField interviews highlight grid bottlenecks in X region. Substation capacities lag behind generation growth rates by 38%... \n\n## Conclusion  \nWhile subsidies accelerate initial adoption, infrastructure-dependent growth requires coordinated policy modernization...\n</code></pre><p><strong>Example 2: Technology Ethics Insights</strong><br><em>(Show shorter structural example within parentheses)</em><br>[Input: Ethical dilemmas from AI deployment case studies]<br>[Output: Structured sections on biases, accountability gaps, mitigation frameworks – no sample text required here as demonstration too long]</p><h2>Notes</h2><ul><li><p>Ensure today's date inclusion in content where relevant (e.g., \"current policies as of <span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span> \").</p></li><li><p>Maintain original insight integrity: Never invent unsupported analysis; flag data limitations if gaps exist.</p></li><li><p>Prioritize depth over brevity; synthesize rather than list insights.</p></li><li><p>If provided insights lack structure (e.g., $1B market size + anecdote + opinion), ask for clarified organization before proceeding.</p></li></ul>"
            }
          ],
          "agentTools": [
            {
              "agentSelectedTool": "currentDateTime",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "agentSelectedTool": "currentDateTime"
              }
            }
          ],
          "agentKnowledgeDocumentStores": "",
          "agentKnowledgeVSEmbeddings": "",
          "agentEnableMemory": true,
          "agentMemoryType": "allMessages",
          "agentUserMessage": "<p>Synthesize the following raw insights, which represent a novel line of inquiry, into a full covering, detailed, comprehensive and well-structured white paper. Ensure the document has a clear title, an executive summary, a detailed analysis section, and a concluding summary. Raw Insights: <span class=\"variable\" data-type=\"mention\" data-id=\"$flow.state.raw_insights\" data-label=\"$flow.state.raw_insights\">{{ $flow.state.raw_insights }}</span>Also, include current time &amp; date: <span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span> </p>",
          "agentReturnResponseAs": "userMessage",
          "agentUpdateState": "",
          "agentModelConfig": {
            "cache": "",
            "modelName": "alibaba/tongyi-deepresearch-30b-a3b:free",
            "temperature": "1",
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "https://openrouter.ai/api/v1",
            "baseOptions": "",
            "agentModel": "chatOpenRouter"
          }
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_1-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    },
    {
      "id": "agentAgentflow_2",
      "type": "agentFlow",
      "position": {
        "x": 850,
        "y": 2609
      },
      "width": 270,
      "height": 101,
      "selected": false,
      "positionAbsolute": {
        "x": 850,
        "y": 2609
      },
      "data": {
        "id": "agentAgentflow_2",
        "label": "Local RAG AI Agent (Archivist)",
        "version": 2,
        "name": "agentAgentflow",
        "type": "Agent",
        "color": "#4DD0E1",
        "baseClasses": [
          "Agent"
        ],
        "category": "Agent Flows",
        "description": "Dynamically choose and utilize tools during runtime, enabling multi-step reasoning",
        "inputParams": [
          {
            "label": "Model",
            "name": "agentModel",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "loadConfig": true,
            "id": "agentAgentflow_2-input-agentModel-asyncOptions",
            "display": true
          },
          {
            "label": "Messages",
            "name": "agentMessages",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Role",
                "name": "role",
                "type": "options",
                "options": [
                  {
                    "label": "System",
                    "name": "system"
                  },
                  {
                    "label": "Assistant",
                    "name": "assistant"
                  },
                  {
                    "label": "Developer",
                    "name": "developer"
                  },
                  {
                    "label": "User",
                    "name": "user"
                  }
                ]
              },
              {
                "label": "Content",
                "name": "content",
                "type": "string",
                "acceptVariable": true,
                "generateInstruction": true,
                "rows": 4
              }
            ],
            "id": "agentAgentflow_2-input-agentMessages-array",
            "display": true
          },
          {
            "label": "OpenAI Built-in Tools",
            "name": "agentToolsBuiltInOpenAI",
            "type": "multiOptions",
            "optional": true,
            "options": [
              {
                "label": "Web Search",
                "name": "web_search_preview",
                "description": "Search the web for the latest information"
              },
              {
                "label": "Code Interpreter",
                "name": "code_interpreter",
                "description": "Write and run Python code in a sandboxed environment"
              },
              {
                "label": "Image Generation",
                "name": "image_generation",
                "description": "Generate images based on a text prompt"
              }
            ],
            "show": {
              "agentModel": "chatOpenAI"
            },
            "id": "agentAgentflow_2-input-agentToolsBuiltInOpenAI-multiOptions",
            "display": false
          },
          {
            "label": "Tools",
            "name": "agentTools",
            "type": "array",
            "optional": true,
            "array": [
              {
                "label": "Tool",
                "name": "agentSelectedTool",
                "type": "asyncOptions",
                "loadMethod": "listTools",
                "loadConfig": true
              },
              {
                "label": "Require Human Input",
                "name": "agentSelectedToolRequiresHumanInput",
                "type": "boolean",
                "optional": true
              }
            ],
            "id": "agentAgentflow_2-input-agentTools-array",
            "display": true
          },
          {
            "label": "Knowledge (Document Stores)",
            "name": "agentKnowledgeDocumentStores",
            "type": "array",
            "description": "Give your agent context about different document sources. Document stores must be upserted in advance.",
            "array": [
              {
                "label": "Document Store",
                "name": "documentStore",
                "type": "asyncOptions",
                "loadMethod": "listStores"
              },
              {
                "label": "Describe Knowledge",
                "name": "docStoreDescription",
                "type": "string",
                "generateDocStoreDescription": true,
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_2-input-agentKnowledgeDocumentStores-array",
            "display": true
          },
          {
            "label": "Knowledge (Vector Embeddings)",
            "name": "agentKnowledgeVSEmbeddings",
            "type": "array",
            "description": "Give your agent context about different document sources from existing vector stores and embeddings",
            "array": [
              {
                "label": "Vector Store",
                "name": "vectorStore",
                "type": "asyncOptions",
                "loadMethod": "listVectorStores",
                "loadConfig": true
              },
              {
                "label": "Embedding Model",
                "name": "embeddingModel",
                "type": "asyncOptions",
                "loadMethod": "listEmbeddings",
                "loadConfig": true
              },
              {
                "label": "Knowledge Name",
                "name": "knowledgeName",
                "type": "string",
                "placeholder": "A short name for the knowledge base, this is useful for the AI to know when and how to search for correct information"
              },
              {
                "label": "Describe Knowledge",
                "name": "knowledgeDescription",
                "type": "string",
                "placeholder": "Describe what the knowledge base is about, this is useful for the AI to know when and how to search for correct information",
                "rows": 4
              },
              {
                "label": "Return Source Documents",
                "name": "returnSourceDocuments",
                "type": "boolean",
                "optional": true
              }
            ],
            "optional": true,
            "id": "agentAgentflow_2-input-agentKnowledgeVSEmbeddings-array",
            "display": true
          },
          {
            "label": "Enable Memory",
            "name": "agentEnableMemory",
            "type": "boolean",
            "description": "Enable memory for the conversation thread",
            "default": true,
            "optional": true,
            "id": "agentAgentflow_2-input-agentEnableMemory-boolean",
            "display": true
          },
          {
            "label": "Memory Type",
            "name": "agentMemoryType",
            "type": "options",
            "options": [
              {
                "label": "All Messages",
                "name": "allMessages",
                "description": "Retrieve all messages from the conversation"
              },
              {
                "label": "Window Size",
                "name": "windowSize",
                "description": "Uses a fixed window size to surface the last N messages"
              },
              {
                "label": "Conversation Summary",
                "name": "conversationSummary",
                "description": "Summarizes the whole conversation"
              },
              {
                "label": "Conversation Summary Buffer",
                "name": "conversationSummaryBuffer",
                "description": "Summarize conversations once token limit is reached. Default to 2000"
              }
            ],
            "optional": true,
            "default": "allMessages",
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_2-input-agentMemoryType-options",
            "display": true
          },
          {
            "label": "Window Size",
            "name": "agentMemoryWindowSize",
            "type": "number",
            "default": "20",
            "description": "Uses a fixed window size to surface the last N messages",
            "show": {
              "agentMemoryType": "windowSize"
            },
            "id": "agentAgentflow_2-input-agentMemoryWindowSize-number",
            "display": false
          },
          {
            "label": "Max Token Limit",
            "name": "agentMemoryMaxTokenLimit",
            "type": "number",
            "default": "2000",
            "description": "Summarize conversations once token limit is reached. Default to 2000",
            "show": {
              "agentMemoryType": "conversationSummaryBuffer"
            },
            "id": "agentAgentflow_2-input-agentMemoryMaxTokenLimit-number",
            "display": false
          },
          {
            "label": "Input Message",
            "name": "agentUserMessage",
            "type": "string",
            "description": "Add an input message as user message at the end of the conversation",
            "rows": 4,
            "optional": true,
            "acceptVariable": true,
            "show": {
              "agentEnableMemory": true
            },
            "id": "agentAgentflow_2-input-agentUserMessage-string",
            "display": true
          },
          {
            "label": "Return Response As",
            "name": "agentReturnResponseAs",
            "type": "options",
            "options": [
              {
                "label": "User Message",
                "name": "userMessage"
              },
              {
                "label": "Assistant Message",
                "name": "assistantMessage"
              }
            ],
            "default": "userMessage",
            "id": "agentAgentflow_2-input-agentReturnResponseAs-options",
            "display": true
          },
          {
            "label": "Update Flow State",
            "name": "agentUpdateState",
            "description": "Update runtime state during the execution of the workflow",
            "type": "array",
            "optional": true,
            "acceptVariable": true,
            "array": [
              {
                "label": "Key",
                "name": "key",
                "type": "asyncOptions",
                "loadMethod": "listRuntimeStateKeys",
                "freeSolo": true
              },
              {
                "label": "Value",
                "name": "value",
                "type": "string",
                "acceptVariable": true,
                "acceptNodeOutputAsVariable": true
              }
            ],
            "id": "agentAgentflow_2-input-agentUpdateState-array",
            "display": true
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "agentModel": "chatOpenRouter",
          "agentMessages": [
            {
              "role": "system",
              "content": "<p>You are a document processor that takes a provided Markdown document, adds a current timestamp to indicate when it was processed, and prepares the result as a clean, standalone Markdown file ready for upload and storage in Google Drive.</p><p>The input will be a Markdown document provided in the user message. Generate the timestamp using the current date and time in ISO 8601 format (e.g., <span class=\"variable\" data-type=\"mention\" data-id=\"current_date_time\" data-label=\"current_date_time\">{{ current_date_time }}</span> T14:30:00Z). Insert it as the first line of the document in the following format:<br><code>&lt;!-- Processed Timestamp: [ISO_TIMESTAMP] --&gt;</code><br>Ensure the rest of the Markdown content remains unchanged. \"Preparing for Google Drive\" means outputting the full modified content as plain text Markdown, with no additional wrappers, metadata, or file extensions—suitable for direct copy-paste into a new .md file in Drive.</p><h1>Steps</h1><ol><li><p>Read the provided Markdown document carefully to understand its structure and content.</p></li><li><p>Generate the current timestamp in ISO 8601 format (UTC timezone preferred; use your system's current time if no external clock is available).</p></li><li><p>Prepend the timestamp line to the very beginning of the document, ensuring it does not disrupt the Markdown rendering (use HTML comment syntax as specified).</p></li><li><p>Verify the output is valid Markdown: no syntax errors introduced, and the timestamp is non-intrusive.</p></li><li><p>Output only the modified document; do not add explanations, headers, or footers unless they were in the original.</p></li></ol><h1>Output Format</h1><p>Output the complete modified Markdown document as plain text, starting directly with the timestamp comment line followed by the original content. Do not use code blocks, quotes, or any enclosing structures. The result should be a single, cohesive Markdown string ready to be saved as a .md file (e.g., length matching the original plus ~30 characters for the timestamp).</p><h1>Examples</h1><p><strong>Example 1:</strong><br><em>Input:</em></p><pre><code># Sample Document\nThis is the body content.\n- List item 1\n- List item 2\n</code></pre><p><em>Output:</em></p><h1>Sample Document</h1><p>This is the body content.</p><ul><li><p>List item 1</p></li><li><p>List item 2</p></li></ul><p><em>(In real scenarios, the input Markdown would be longer and more complex, such as full articles or reports; use placeholders like [FULLMDCONTENT] for even more detailed examples if needed.)</em></p><p><strong>Example 2:</strong><br><em>Input:</em></p><pre><code>## Heading  \nParagraph with **bold** text.\n</code></pre><p><em>Output:</em></p><h2>Heading</h2><p>Paragraph with <strong>bold</strong> text.</p><h1>Notes</h1><ul><li><p>If the original document already starts with a comment or frontmatter, insert the timestamp before it to maintain order.</p></li><li><p>Edge case: Empty document—output only the timestamp line.</p></li><li><p>Always use UTC for timestamps to ensure consistency across timezones; avoid local time unless specified.</p></li><li><p>Do not alter any original content, links, images, or formatting in the Markdown.</p></li></ul>"
            }
          ],
          "agentTools": [
            {
              "agentSelectedTool": "googleDriveTool",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "driveType": "search",
                "searchActions": "[\"searchFiles\"]",
                "agentSelectedTool": "googleDriveTool"
              }
            },
            {
              "agentSelectedTool": "currentDateTime",
              "agentSelectedToolRequiresHumanInput": "",
              "agentSelectedToolConfig": {
                "agentSelectedTool": "currentDateTime"
              }
            }
          ],
          "agentKnowledgeDocumentStores": "",
          "agentKnowledgeVSEmbeddings": "",
          "agentEnableMemory": true,
          "agentMemoryType": "allMessages",
          "agentUserMessage": "<p><span class=\"variable\" data-type=\"mention\" data-id=\"executeFlowAgentflow_0\" data-label=\"executeFlowAgentflow_0\">{{ executeFlowAgentflow_0 }}</span></p>",
          "agentReturnResponseAs": "userMessage",
          "agentUpdateState": "",
          "agentModelConfig": {
            "cache": "",
            "modelName": "x-ai/grok-4-fast:free",
            "temperature": 0.9,
            "streaming": true,
            "maxTokens": "",
            "topP": "",
            "frequencyPenalty": "",
            "presencePenalty": "",
            "timeout": "",
            "basepath": "https://openrouter.ai/api/v1",
            "baseOptions": "",
            "agentModel": "chatOpenRouter"
          }
        },
        "outputAnchors": [
          {
            "id": "agentAgentflow_2-output-agentAgentflow",
            "label": "Agent",
            "name": "agentAgentflow"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "startAgentflow_0",
      "sourceHandle": "startAgentflow_0-output-startAgentflow",
      "target": "executeFlowAgentflow_0",
      "targetHandle": "executeFlowAgentflow_0",
      "data": {
        "sourceColor": "#7EE787",
        "targetColor": "#a3b18a",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "startAgentflow_0-startAgentflow_0-output-startAgentflow-executeFlowAgentflow_0-executeFlowAgentflow_0"
    },
    {
      "source": "executeFlowAgentflow_0",
      "sourceHandle": "executeFlowAgentflow_0-output-executeFlowAgentflow",
      "target": "agentAgentflow_0",
      "targetHandle": "agentAgentflow_0",
      "data": {
        "sourceColor": "#a3b18a",
        "targetColor": "#4DD0E1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "executeFlowAgentflow_0-executeFlowAgentflow_0-output-executeFlowAgentflow-agentAgentflow_0-agentAgentflow_0"
    },
    {
      "source": "agentAgentflow_0",
      "sourceHandle": "agentAgentflow_0-output-agentAgentflow",
      "target": "conditionAgentAgentflow_0",
      "targetHandle": "conditionAgentAgentflow_0",
      "data": {
        "sourceColor": "#4DD0E1",
        "targetColor": "#ff8fab",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "agentAgentflow_0-agentAgentflow_0-output-agentAgentflow-conditionAgentAgentflow_0-conditionAgentAgentflow_0"
    },
    {
      "source": "conditionAgentAgentflow_0",
      "sourceHandle": "conditionAgentAgentflow_0-output-0",
      "target": "agentAgentflow_1",
      "targetHandle": "agentAgentflow_1",
      "data": {
        "sourceColor": "#ff8fab",
        "targetColor": "#4DD0E1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentAgentflow_0-conditionAgentAgentflow_0-output-0-agentAgentflow_1-agentAgentflow_1"
    },
    {
      "source": "conditionAgentAgentflow_0",
      "sourceHandle": "conditionAgentAgentflow_0-output-1",
      "target": "llmAgentflow_0",
      "targetHandle": "llmAgentflow_0",
      "data": {
        "sourceColor": "#ff8fab",
        "targetColor": "#64B5F6",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "conditionAgentAgentflow_0-conditionAgentAgentflow_0-output-1-llmAgentflow_0-llmAgentflow_0"
    },
    {
      "source": "llmAgentflow_0",
      "sourceHandle": "llmAgentflow_0-output-llmAgentflow",
      "target": "loopAgentflow_0",
      "targetHandle": "loopAgentflow_0",
      "data": {
        "sourceColor": "#64B5F6",
        "targetColor": "#FFA07A",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "llmAgentflow_0-llmAgentflow_0-output-llmAgentflow-loopAgentflow_0-loopAgentflow_0"
    },
    {
      "source": "agentAgentflow_1",
      "sourceHandle": "agentAgentflow_1-output-agentAgentflow",
      "target": "agentAgentflow_2",
      "targetHandle": "agentAgentflow_2",
      "data": {
        "sourceColor": "#4DD0E1",
        "targetColor": "#4DD0E1",
        "isHumanInput": false
      },
      "type": "agentFlow",
      "id": "agentAgentflow_1-agentAgentflow_1-output-agentAgentflow-agentAgentflow_2-agentAgentflow_2"
    }
  ]
}